# -*- coding: utf-8 -*-
"""Streamlit_app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oyPqCiBzBZa2C9lGJltpOJYTFOQXZu2J
"""

import streamlit as st
import joblib
import os
import re
import numpy as np
from scipy.sparse import hstack

# =======================
# Paths
# =======================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
MODEL_DIR = os.path.join(BASE_DIR, "models")

# =======================
# Load models (cached)
# =======================
@st.cache_resource
def load_models():
    tfidf = joblib.load(os.path.join(MODEL_DIR, "tfidf.pkl"))
    scaler = joblib.load(os.path.join(MODEL_DIR, "scaler.pkl"))
    clf = joblib.load(os.path.join(MODEL_DIR, "classifier.pkl"))
    reg = joblib.load(os.path.join(MODEL_DIR, "regressor.pkl"))
    return tfidf, scaler, clf, reg

tfidf, scaler, clf, reg = load_models()

# =======================
# Keywords
# =======================
keywords = [
    'dp', 'dynamic programming', 'recursion', 'backtracking',
    'greedy', 'divide and conquer', 'graph', 'tree', 'dfs', 'bfs',
    'shortest path', 'dijkstra', 'bellman ford', 'topological',
    'mst', 'lca', 'segment tree', 'fenwick', 'binary indexed tree',
    'heap', 'priority queue', 'deque', 'binary search', 'two pointers',
    'sliding window', 'bitmask', 'bit manipulation', 'flow', 'max flow',
    'min cost', 'matching', 'combinatorics', 'probability', 'modulo'
]

# =======================
# Text cleaning
# =======================
def clean_text(text):
    text = text.lower()
    text = re.sub(r'\s+', ' ', text).strip()
    text = re.sub(r"[^a-z0-9+\-*/=^<>% ]", "", text)
    return text

# =======================
# Feature extraction
# =======================
@st.cache_data
def extract_features(title, description, input_desc, output_desc):
    combined_text = " ".join([title, description, input_desc, output_desc])
    combined_text = clean_text(combined_text)

    # TF-IDF vector
    X_tfidf = tfidf.transform([combined_text])

    # Extra features
    text_length = len(combined_text)
    word_count = len(combined_text.split())
    math_symbols = sum(combined_text.count(s) for s in "+-*/=^<>%")
    keyword_counts = [combined_text.count(kw) for kw in keywords]

    extra_features = np.array([[text_length, word_count, math_symbols] + keyword_counts])
    extra_features_scaled = scaler.transform(extra_features)

    # Combine
    X_final = hstack([X_tfidf, extra_features_scaled])
    return X_final

# =======================
# Streamlit UI
# =======================
st.set_page_config(page_title="Codeforces Difficulty Predictor")
st.title("Codeforces Problem Difficulty Predictor")
st.write("Predict the difficulty class and rating of a Codeforces problem from text.")

# Input fields
title = st.text_input("Problem Title")
description = st.text_area("Problem Description")
input_desc = st.text_area("Input Description")
output_desc = st.text_area("Output Description")

# Predict button
if st.button("Predict"):
    if not description.strip():
        st.warning("Please enter at least a problem description.")
    else:
        with st.spinner("Predicting..."):
            X_input = extract_features(title, description, input_desc, output_desc)
            predicted_class = clf.predict(X_input)[0]
            predicted_score = int(round(np.clip(reg.predict(X_input)[0], 800, 3500)))

        # Show results
        st.success(f"Predicted Difficulty Class: **{predicted_class}**")
        st.info(f"Predicted Difficulty Score: **{predicted_score}**")
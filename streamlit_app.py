# -*- coding: utf-8 -*-
"""Streamlit_app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oyPqCiBzBZa2C9lGJltpOJYTFOQXZu2J
"""

!pip install streamlit

import streamlit as st
print(st.__version__)

import streamlit as st
import joblib
import os
import re
import numpy as np
from scipy.sparse import hstack

# =======================
# Paths
# =======================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
MODEL_DIR = os.path.join(BASE_DIR, "models")

# =======================
# Load models (cached)
# =======================
@st.cache_resource
def load_models():
    tfidf = joblib.load(os.path.join(MODEL_DIR, "tfidf.pkl"))
    scaler = joblib.load(os.path.join(MODEL_DIR, "scaler.pkl"))
    clf = joblib.load(os.path.join(MODEL_DIR, "classifier.pkl"))
    reg = joblib.load(os.path.join(MODEL_DIR, "regressor.pkl"))
    return tfidf, scaler, clf, reg

tfidf, scaler, clf, reg = load_models()

# =======================
# Keywords
# =======================
keywords = [
    'dp', 'dynamic programming', 'recursion', 'backtracking',
    'greedy', 'divide and conquer', 'graph', 'tree', 'dfs', 'bfs',
    'shortest path', 'dijkstra', 'bellman ford', 'topological',
    'mst', 'lca', 'segment tree', 'fenwick', 'binary indexed tree',
    'heap', 'priority queue', 'deque', 'binary search', 'two pointers',
    'sliding window', 'bitmask', 'bit manipulation', 'flow', 'max flow',
    'min cost', 'matching', 'combinatorics', 'probability', 'modulo'
]

# =======================
# Text cleaning
# =======================
def clean_text(text):
    text = text.lower()
    text = re.sub(r'\s+', ' ', text).strip()
    text = re.sub(r"[^a-z0-9+\-*/=^<>% ]", "", text)
    return text

# =======================
# Feature extraction
# =======================
def extract_features(title, description, input_desc, output_desc):
    combined_text = " ".join([title, description, input_desc, output_desc])
    combined_text = clean_text(combined_text)

    X_tfidf = tfidf.transform([combined_text])
    text_length = len(combined_text)
    word_count = len(combined_text.split())
    math_symbols = sum(combined_text.count(s) for s in "+-*/=^<>%")
    keyword_counts = [combined_text.count(kw) for kw in keywords]

    extra_features = np.array([[text_length, word_count, math_symbols] + keyword_counts])
    extra_features_scaled = scaler.transform(extra_features)
    X_final = hstack([X_tfidf, extra_features_scaled])
    return X_final

# =======================
# Streamlit UI
# =======================
st.title("Codeforces Problem Difficulty Predictor")
st.write("Predict the difficulty class and rating of a Codeforces problem from text.")

title = st.text_input("Problem Title")
description = st.text_area("Problem Description")
input_desc = st.text_area("Input Description")
output_desc = st.text_area("Output Description")

if st.button("Predict"):
    if not description.strip():
        st.warning("Please enter at least a problem description.")
    else:
        X_input = extract_features(title, description, input_desc, output_desc)
        predicted_class = clf.predict(X_input)[0]
        predicted_score = reg.predict(X_input)[0]
        predicted_score = np.clip(predicted_score, 800, 3500)
        predicted_score = int(round(predicted_score))

        st.success(f"Predicted Difficulty Class: **{predicted_class}**")
        st.info(f"Predicted Difficulty Score: **{predicted_score}**")